{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  1. **EDA**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Description\n",
    "\n",
    "### 1) Experimental Protocol Details\n",
    "The data used in this project was collected during tests session in the Wyss Motion Capture Lab, where 6 human subjects were asked to wear the soft sensing shirt and perform a series of arm motions. Each subject performed 3 trials of arm movements. Each trial contains 3 sequential conditions: \n",
    "\n",
    "* Pre-defined movements\n",
    "* Composite movements \n",
    "* Random movements \n",
    "\n",
    "Pre-defined movements include shoulder abduction, flexion, extension, horizontal flexion, and horizontal extension; all from minimum to maximum range of motion. \n",
    "Composite movements include drawing a figure “∞” with the arm at different heights.\n",
    "Random movements were trials where the subject was told to move the arm in a random manner for the duration of the trial.\n",
    "The total number of observations (n) for these subjects are: 80137, 102941, 91690, 118276, 100600, and 108239.\n",
    "\n",
    "\n",
    "\n",
    "### 2) Collected Data\n",
    "Recorded data from each session includes timestamps, embedded sensor raw outputs (total of 6 sensors in the shirt), and the motion captured (MOCAP) shoulder angles (total of 3 degrees of freedom: shoulder adduction, horizontal flexion, and internal rotation). The MOCAP data is used as the angle ground truth. Therefore, the dataset has 7 initial predictors and 3 outcome variables.\n",
    "\n",
    "#### 2a) Description of Raw Data? \n",
    "\n",
    "### 3) Data Cleaning\n",
    "One thing that needed to be considered when first looking at the data is the fact in the variability present in ranges of values presented by the MOCAP data for the three angles: Abduction (ab), Horizontal Flexion (hf) and Internal Rotation (ir). This corresponds to the range of motion across all subjects in the three directions. Although the ranges are relatively consistent across the 6 subjects for hf and ab, the ir ranges fluctuate considerably. The variability here could be due to true inter-subject variability (linked to posture), as well as the lack of standardization of the definition of 0&deg; rotation in ir during the experimental data collection. Since the MOCAP is used as the ground truth for the model predictions, it was decided to develop a model using the data of a single subject to avoid any complications arising from using an inconsistent ground truth for ir across multiple subjects. This aligns with the goal of creating a model that would have a personalized calibration period for each individual who would use it to train the model, and then have the model predict for each subject. Later on, it may be worth extending the model to be more general, but the use case for the scope of this project to be a subject-individualized model. \n",
    "\n",
    "\n",
    "### 4) Dataset Selection\n",
    "Once the decision to pursue a single-subject model, a single subject was selected from the 6 total subjects that were tested in the protocol. The data from the three separate trials, each containing the three conditions of pre-defined, composite, and random movements, were pooled together. Additionally, since the sampling frequency of the MOCAP system is very high (200 Hz), the dataset was downsampled to allow for faster computation time. \n",
    "\n",
    "### 5) Feature Selection and Engineering\n",
    "For the initial data exploration, the timestamp data was dropped in order to remove absolute time-dependency from the model. This was done to mitigate the risk of the model being biased towards a certain outcome based on what time the motion was recorded since the protocol involved following a sequence of moments, which will not always be the case in later trials. \n",
    "\n",
    "However, since the arm motions are continuous, including previous sensor values may be useful in the models, especially in RNN and LSTM models, to predict future positions of the arm. For this purpose, the 1st and 2nd derivatives of the position of the arm were calculated and included as features. Additionally, for linear regression, polynomial features of order 2 were included as well. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
